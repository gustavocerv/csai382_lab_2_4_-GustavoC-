{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb525193-b69b-4ca1-bc7a-eba7be1a83ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part 1 — Load the Data**\n",
    "\n",
    "In this step, we load the two raw STEDI datasets from the bronze layer into Spark DataFrames.\n",
    "These tables contain the original, unprocessed data that will be cleaned and curated in later steps.\n",
    "\n",
    "**device_message_raw** contains continuous sensor readings\n",
    "\n",
    "**rapid_step_test_raw** contains step test sessions with start and stop times\n",
    "\n",
    "Previewing the data helps verify that the tables loaded correctly and that the schemas match expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a640a23-8bf5-4df7-ae03-4f57835a1fe2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract Numeric Distance and Add Constant Column"
    }
   },
   "outputs": [],
   "source": [
    "df_device = spark.table(\"workspace.bronze.device_messages\")\n",
    "df_steps = spark.table(\"workspace.bronze.rapid_step_tests\")\n",
    "\n",
    "# Preview tables\n",
    "display(df_device)\n",
    "display(df_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15b4bfb9-968b-406d-913d-b557870eb58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part 2 — Prepare Each Table**\n",
    "\n",
    "Before aligning the datasets, we need to clean and enrich them so they are easier to work with and clearly documented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e1d372c-4c23-4d9d-9955-e2e583d3a60d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**A. Clean / Convert Distance**\n",
    "\n",
    "The distance column in the device messages table is stored as a string.\n",
    "Machine learning models require numeric values, so we extract the numeric portion and convert it to an integer.\n",
    "This creates a new column called **distance_cm** that can be used for analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0f9c01d-371a-49d7-975d-30e33563e2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col, lit\n",
    "\n",
    "# Extract numeric distance from string (e.g., \"1cm\" → 1)\n",
    "df_device = df_device.withColumn(\n",
    "    \"distance_cm\", regexp_extract(col(\"distance\"), r\"(\\d+)\", 1).cast(\"int\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b157fd89-43d1-44ce-80c9-c8f7f00a4794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**B. Add Source Labels**\n",
    "\n",
    "To maintain data traceability, we add a source column to both datasets.\n",
    "\n",
    "Rows from **device_message_raw** are labeled as \"**device**\"\n",
    "\n",
    "Rows from **rapid_step_test_raw** are labeled as \"**step**\"\n",
    "\n",
    "This makes it clear where each record originated and helps with debugging and validation later in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c40237-c701-45ab-bd0f-91d01d87df83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_device = df_device.withColumn(\"source\", lit(\"device\"))\n",
    "df_steps = df_steps.withColumn(\"source\", lit(\"step\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d99fb6af-113a-40e8-85d3-8173a5363451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part 3 — Label Each Sensor Reading**\n",
    "\n",
    "This is the most important step of the ETL process.\n",
    "Here, we determine whether each sensor reading occurred during a real stepping session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12cddf60-a930-4b0f-a116-2ecca55e1d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**A. Extract Step Windows**\n",
    "\n",
    "Each Rapid Step Test includes a **start_time** and **stop_time** that define when the user was actively stepping.\n",
    "We extract only the necessary columns (**device_id**, **start_time**, and **stop_time**) to create clean step windows that will be used for timestamp alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246c4dc3-9cb7-4d03-8279-86b1b5c2d845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_steps_window = df_steps.select(\n",
    "    col(\"device_id\"),\n",
    "    col(\"start_time\"),\n",
    "    col(\"stop_time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acbdbc29-7127-4d37-9deb-a58109ac469e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**B. Join Device Messages with Step Windows**\n",
    "\n",
    "We perform a **left join** between device messages and step windows using:\n",
    "\n",
    "Matching **device_id**\n",
    "\n",
    "A timestamp condition where the sensor timestamp falls between the step test start and stop times\n",
    "\n",
    "If a sensor reading falls inside a step window, it is labeled as \"**step**\".\n",
    "If it does not, it is labeled as \"**no_step**\".\n",
    "This produces a labeled dataset suitable for supervised machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d86850-64a2-4062-b8d9-023bd9e5b7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_labeled = (\n",
    "    df_device.alias(\"d\")\n",
    "    .join(\n",
    "        df_steps_window.alias(\"s\"),\n",
    "        (col(\"d.device_id\") == col(\"s.device_id\")) &\n",
    "        (col(\"d.timestamp\").between(col(\"s.start_time\"), col(\"s.stop_time\"))),\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"step_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), \"step\").otherwise(\"no_step\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad5085ca-2377-4b81-9c4c-58832306f85e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part 4 — Keep Only the Required Columns**\n",
    "\n",
    "After labeling the data, we select only the columns required for the curated (silver layer) dataset:\n",
    "\n",
    "**timestamp**\n",
    "\n",
    "**sensor_type**\n",
    "\n",
    "**distance_cm**\n",
    "\n",
    "**device_id**\n",
    "\n",
    "**step_label**\n",
    "\n",
    "**source**\n",
    "\n",
    "Removing unnecessary columns keeps the dataset clean, efficient, and focused on modeling needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927b900a-7ee1-443c-a869-767c821e771c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select Non-Ambiguous Columns After Join"
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_labeled.select(\n",
    "    \"timestamp\",\n",
    "    \"sensor_type\",\n",
    "    \"distance_cm\",\n",
    "    \"d.device_id\",\n",
    "    \"step_label\",\n",
    "    \"source\"\n",
    ")\n",
    "\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "238dca17-0a25-4c83-8eab-d5f0936da4de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part 5 — Save Curated Dataset**\n",
    "\n",
    "In this step, we save the curated dataset as a managed table in the Databricks catalog.\n",
    "This table represents the **silver layer** of the data pipeline and will be used later for machine-learning tasks.\n",
    "The dataset is saved in overwrite mode to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8bb069b-a6f2-4720-a5f0-a6c27756d319",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Curated Table for ML"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE workspace.silver\")\n",
    "\n",
    "# Save as a table for ML, allowing schema overwrite\n",
    "df_final.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"labeled_step_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c4d445a-5854-4f83-8fd0-f64bee1778be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part 6 — Verify Labels (SQL Queries)**\n",
    "\n",
    "Validation ensures the ETL process worked correctly and that labels are clean and consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91009b44-7ba1-4759-90ee-cd5d97a510aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Check Step vs No Step Counts**\n",
    "\n",
    "This query counts how many rows are labeled as **step** versus **no_step**.\n",
    "Both values should be present, and the counts should make logical sense based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3cfda9-d96c-42bc-8668-0e289342b552",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT\n",
    "  step_label,\n",
    "  COUNT(*) AS row_count\n",
    "FROM labeled_step_test\n",
    "GROUP BY step_label;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc1d17cc-69a0-4b9d-bc33-d9e1ccac524a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Check for Invalid Step Labels**\n",
    "This query checks for any rows with missing or invalid step_label values.\n",
    "A correct dataset should return zero rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b6f7cd-65fe-4e31-a396-756426beae5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT *\n",
    "FROM labeled_step_test\n",
    "WHERE step_label NOT IN ('step', 'no_step')\n",
    "   OR step_label IS NULL\n",
    "LIMIT 50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361445a9-52cd-42ba-bbd7-93877021dc00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Check Source Labels**\n",
    "\n",
    "This query verifies that all rows are properly labeled as either **device** or **step** in the **source** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a774e6-f5a2-43c7-937a-fd41dfeeb2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT\n",
    "  source,\n",
    "  COUNT(*) AS row_count\n",
    "FROM labeled_step_test\n",
    "GROUP BY source;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "377023b8-dd9d-49a2-a215-1ec0c9a69f67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Check for Invalid Source Labels**\n",
    "\n",
    "This final validation ensures there are no null or unexpected values in the **source** column.\n",
    "Returning zero rows confirms the dataset is clean and ready for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c451758-ed64-459f-b0ec-eaefaea6e0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT *\n",
    "FROM labeled_step_test\n",
    "WHERE source NOT IN ('device', 'step')\n",
    "   OR source IS NULL\n",
    "LIMIT 50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61b4d501-3a4e-4573-9582-7dd0a66078c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Final Step — Persist the Curated Silver Dataset**\n",
    "\n",
    "In this step, we save the fully curated and labeled dataset as a managed table in Databricks.\n",
    "The dataset is written using **overwrite mode** to ensure the table can be recreated consistently if the ETL process is rerun.\n",
    "Saving the data as a table allows it to be easily queried using SQL and reused in future assignments, including the machine-learning project later in the course.\n",
    "This table represents the silver layer of the STEDI data pipeline, containing clean, structured, and labeled data ready for modeling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88b240ea-a8c2-465a-a642-6501f80027ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.mode(\"overwrite\").saveAsTable(\"labeled_step_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e25c77d4-36d1-4624-9c25-f601e8f13e05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ethics Check**\n",
    "\n",
    "**Are we labeling data fairly?**\n",
    "The labeling process uses clear, consistent criteria for 'step' and 'no_step', minimizing bias and ensuring fairness across all samples.\n",
    "\n",
    "**Are we protecting identity?**\n",
    "The dataset does not include personally identifiable information; all sensitive data is excluded or anonymized to protect participant privacy.\n",
    "\n",
    "**Are we avoiding medical claims?**\n",
    "The dataset and analysis do not make medical diagnoses or claims. All results are intended for research and educational purposes only."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4599484316281803,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3.3 ETL Pipelines: Curate Dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
