{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a640a23-8bf5-4df7-ae03-4f57835a1fe2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract Numeric Distance and Add Constant Column"
    }
   },
   "outputs": [],
   "source": [
    "df_device = spark.table(\"workspace.bronze.device_messages\")\n",
    "df_steps = spark.table(\"workspace.bronze.rapid_step_tests\")\n",
    "\n",
    "# Preview tables\n",
    "display(df_device)\n",
    "display(df_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0f9c01d-371a-49d7-975d-30e33563e2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col, lit\n",
    "\n",
    "# Extract numeric distance from string (e.g., \"1cm\" â†’ 1)\n",
    "df_device = df_device.withColumn(\n",
    "    \"distance_cm\", regexp_extract(col(\"distance\"), r\"(\\d+)\", 1).cast(\"int\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c40237-c701-45ab-bd0f-91d01d87df83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_device = df_device.withColumn(\"source\", lit(\"device\"))\n",
    "df_steps = df_steps.withColumn(\"source\", lit(\"step\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246c4dc3-9cb7-4d03-8279-86b1b5c2d845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_steps_window = df_steps.select(\n",
    "    col(\"device_id\"),\n",
    "    col(\"start_time\"),\n",
    "    col(\"stop_time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d86850-64a2-4062-b8d9-023bd9e5b7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_labeled = (\n",
    "    df_device.alias(\"d\")\n",
    "    .join(\n",
    "        df_steps_window.alias(\"s\"),\n",
    "        (col(\"d.device_id\") == col(\"s.device_id\")) &\n",
    "        (col(\"d.timestamp\").between(col(\"s.start_time\"), col(\"s.stop_time\"))),\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"step_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), \"step\").otherwise(\"no_step\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927b900a-7ee1-443c-a869-767c821e771c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select Non-Ambiguous Columns After Join"
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_labeled.select(\n",
    "    \"timestamp\",\n",
    "    \"sensor_type\",\n",
    "    \"distance_cm\",\n",
    "    \"d.device_id\",\n",
    "    \"step_label\",\n",
    "    \"source\"\n",
    ")\n",
    "\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8bb069b-a6f2-4720-a5f0-a6c27756d319",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Curated Table for ML"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE workspace.silver\")\n",
    "\n",
    "# Save as a table for ML, allowing schema overwrite\n",
    "df_final.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"labeled_step_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3cfda9-d96c-42bc-8668-0e289342b552",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT\n",
    "  step_label,\n",
    "  COUNT(*) AS row_count\n",
    "FROM labeled_step_test\n",
    "GROUP BY step_label;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b6f7cd-65fe-4e31-a396-756426beae5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT *\n",
    "FROM labeled_step_test\n",
    "WHERE step_label NOT IN ('step', 'no_step')\n",
    "   OR step_label IS NULL\n",
    "LIMIT 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a774e6-f5a2-43c7-937a-fd41dfeeb2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT\n",
    "  source,\n",
    "  COUNT(*) AS row_count\n",
    "FROM labeled_step_test\n",
    "GROUP BY source;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c451758-ed64-459f-b0ec-eaefaea6e0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- %sql\n",
    "SELECT *\n",
    "FROM labeled_step_test\n",
    "WHERE source NOT IN ('device', 'step')\n",
    "   OR source IS NULL\n",
    "LIMIT 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88b240ea-a8c2-465a-a642-6501f80027ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.mode(\"overwrite\").saveAsTable(\"labeled_step_test\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4599484316281803,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3.3 ETL Pipelines: Curate Dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
