{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fbb8677-b712-434d-978b-7d5ec48ed4b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 1: Load transformed data, labels, and prepare arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a578919f-d9b0-4409-ba62-5d37d4b8386f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "pipeline = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/stedi_feature_pipeline.pkl\"\n",
    ")\n",
    "X_train_transformed = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/X_train_transformed.pkl\"\n",
    ")\n",
    "X_test_transformed = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/X_test_transformed.pkl\"\n",
    ")\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "   \"\"\"\n",
    "   Ensures that input arrays (possibly object-dtype, sparse, or 0-d) are converted to a 2-D float matrix.\n",
    "   This is necessary because saved feature arrays may have inconsistent shapes or types after transformation,\n",
    "   and ML models require numeric 2-D arrays for training and prediction.\n",
    "   \"\"\"\n",
    "   if arr.ndim == 0:\n",
    "       # Handle 0-d array directly\n",
    "       arr = arr.item()\n",
    "       if issparse(arr):\n",
    "           arr = arr.toarray()\n",
    "       arr = np.array(arr, dtype=float)\n",
    "   elif arr.dtype == object:\n",
    "       arr = np.array([\n",
    "           x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "           for x in arr\n",
    "       ])\n",
    "       arr = np.vstack(arr)\n",
    "   elif issparse(arr):\n",
    "       arr = arr.toarray()\n",
    "   else:\n",
    "       arr = np.array(arr, dtype=float)\n",
    "   return arr\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "y_train = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/y_train.pkl\"\n",
    ")\n",
    "y_test = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/y_test.pkl\"\n",
    ")\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92fd9601-2702-492d-aa3d-a90133b3704d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 2: Train and evaluate a Logistic Regression baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ead6dc-41be-4028-98cb-0f737fa2ec81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c3518e8-88ac-4e80-ae26-16b2e4567b59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 3: Train and evaluate a Random Forest baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8950af4a-9547-4e97-b9a0-a4957cf4dae7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12b0eb3e-1bef-415d-8b49-71e648ffea38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 4: Compare baseline model accuracy results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "894c25ba-ded4-48d0-b314-7747b992c61e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "383a4b72-0b96-4be2-afa3-7b63632138ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 5: Save trained models and accuracy metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43c8e04-a4e5-4e6d-b0d7-f3d71f9b75b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a unique folder name (prevents overwriting files)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_dir = f\"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/stedi_models/{run_id}\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(log_reg, f\"{base_dir}/log_reg.joblib\")\n",
    "joblib.dump(rf, f\"{base_dir}/random_forest.joblib\")\n",
    "\n",
    "# Save accuracy information (metadata)\n",
    "metadata = {\n",
    "    \"run_id\": run_id,\n",
    "    \"logistic_regression_accuracy\": float(log_reg_score),\n",
    "    \"random_forest_accuracy\": float(rf_score),\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, f\"{base_dir}/metadata.joblib\")\n",
    "\n",
    "base_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a92796a3-8e40-4e61-81f7-9e8c8f5236ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 6: Package saved models and metadata into a ZIP file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "048cbaf2-f21f-4796-bfaf-5b02f37d2cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Define the ZIP path (same folder as your models)\n",
    "zip_path = f\"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/stedi_models_{run_id}.zip\"\n",
    "\n",
    "# Create the ZIP archive containing your saved models and metadata\n",
    "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', base_dir)\n",
    "\n",
    "print(f\"ZIP file created: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "418d6974-ff38-4f33-8c32-aab24395867f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Baseline Model Analysis**\n",
    "\n",
    "The Random Forest model worked better than the Logistic Regression model because it had higher accuracy. Random Forest is also more stable when working with noisy sensor data because it can handle errors and small changes in the data better than Logistic Regression. One question I have is why the accuracy numbers are different and how the features in the data helped Random Forest learn better patterns. It is important to test a model before using it in real life because a wrong prediction can cause bad decisions or problems in real systems. If a model is wrong, it can affect users, workers, or people who depend on the systemâ€™s results. Fairness matters in data science because models should treat everyone equally, and it matters in discipleship because we are taught to care for others and avoid causing harm through our choices."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.4 Trained ML Models: Compare Models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
