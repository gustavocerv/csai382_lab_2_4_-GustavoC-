{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7918c58-577b-4d65-9d9d-320c3871b579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Load Pipeline, Data, and Prepare Matrices**\n",
    "The preprocessing pipeline, transformed training data, and test data are loaded from saved .pkl files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "193c9251-8442-4bc0-930b-d90c7dab43fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "pipeline = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/stedi_feature_pipeline.pkl\"\n",
    ")\n",
    "X_train_transformed = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/X_train_transformed.pkl\"\n",
    ")\n",
    "X_test_transformed = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/X_test_transformed.pkl\"\n",
    ")\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "   \"\"\"\n",
    "   Ensures that input arrays (possibly object-dtype, sparse, or 0-d) are converted to a 2-D float matrix.\n",
    "   This is necessary because saved feature arrays may have inconsistent shapes or types after transformation,\n",
    "   and ML models require numeric 2-D arrays for training and prediction.\n",
    "   \"\"\"\n",
    "   if arr.ndim == 0:\n",
    "       # Handle 0-d array directly\n",
    "       arr = arr.item()\n",
    "       if issparse(arr):\n",
    "           arr = arr.toarray()\n",
    "       arr = np.array(arr, dtype=float)\n",
    "   elif arr.dtype == object:\n",
    "       arr = np.array([\n",
    "           x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "           for x in arr\n",
    "       ])\n",
    "       arr = np.vstack(arr)\n",
    "   elif issparse(arr):\n",
    "       arr = arr.toarray()\n",
    "   else:\n",
    "       arr = np.array(arr, dtype=float)\n",
    "   return arr\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test = to_float_matrix(X_test_transformed)\n",
    "y_train = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/y_train.pkl\"\n",
    ")\n",
    "y_test = joblib.load(\n",
    "   \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/y_test.pkl\"\n",
    ")\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c92493b-8aa5-40ff-a4c6-13777276540e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Review Your SHAP Insights**\n",
    "\n",
    "The most important feature in the model was num__distance_cm. This feature had a much higher importance than the others, which makes sense because step detection should mainly depend on movement distance.\n",
    "\n",
    "A concerning behavior was that the model predicted almost everything as step. It failed to correctly detect the no_step class, which shows a class imbalance problem.\n",
    "\n",
    "This indicates a weakness in the model because it is biased toward the majority class and does not learn the minority class well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd79e701-aa6a-41c6-a0df-84751e0320e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Focused Hyperparameter Grid**\n",
    "\n",
    "The original model showed high accuracy but completely failed to detect the no_step class. This indicates the model is biased toward the majority class.\n",
    "\n",
    "To address this, I will run a focused hyperparameter search on the Logistic Regression regularization parameter C. This may help the model better learn patterns for the minority class.\n",
    "\n",
    "I selected a small grid of C values to test different levels of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1313dc48-1254-4eaf-8fe0-dae885637269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=300),\n",
    "    params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.best_params_, grid.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81708a6c-3873-4757-8d6a-5d4f93c01769",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Model Comparison**\n",
    "\n",
    "Old model score:\n",
    "The original model achieved about 0.95 accuracy on the test set but completely failed to detect the no_step class.\n",
    "\n",
    "New tuned model score:\n",
    "The refined model with C = 0.001 achieved a cross-validation accuracy of 0.9511.\n",
    "\n",
    "Did the new tuning improve performance?\n",
    "Yes, the performance improved slightly.\n",
    "\n",
    "Will you switch to the new model?\n",
    "Yes. Even though the improvement is small, the new model performs slightly better and is the result of a more focused and responsible tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b89ad315-77d7-494e-8b5f-b333ccb79c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(grid.best_estimator_,\n",
    "            \"/Workspace/Users/gsc314@ensign.edu/csai382_lab_2_4_-GustavoC-/etl_pipeline/newstedi_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ee1d047-0dbc-4fbc-89c3-4f1925e5f281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Model Refinement Summary**\n",
    "\n",
    "I performed a second, focused hyperparameter tuning on the Logistic Regression model. The original model showed high accuracy but failed to detect the no_step class, indicating a bias toward the majority class.\n",
    "\n",
    "To improve this, I tuned the regularization parameter C using a small and targeted grid. The best result was achieved with C = 0.001, which slightly improved the overall accuracy.\n",
    "\n",
    "Since the refined model performed better, I updated the final saved model. This decision is responsible because it follows a careful evaluation process and ensures that the final model is based on the best available configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ffa57c4-52cc-4a6d-9299-81ae510a53ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ethics Reflection**\n",
    "\n",
    "Careless hyperparameter tuning could create unfair or unsafe models because it may hide weaknesses, such as ignoring minority classes or producing misleading accuracy scores. If tuning is done without careful evaluation, the model might appear accurate but fail in important real-world situations.\n",
    "\n",
    "It is important to examine model behavior carefully so that we understand its strengths and weaknesses. Explainability tools like SHAP help reveal how the model makes decisions and prevent hidden biases.\n",
    "\n",
    "Gospel principles such as honesty, integrity, and accountability guide me to report results truthfully and make careful decisions. Being honest about model limitations helps build trust and ensures that technology is used responsibly."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.6 Hyperparameter tuning choose model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
